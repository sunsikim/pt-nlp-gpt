{
  "model": {
    "block_size": 256,
    "n_layer": 6,
    "n_head": 6,
    "n_embd": 384,
    "dropout": 0.2,
    "bias": false
  },
  "optimizer": {
    "weight_decay": 1e-1,
    "learning_rate": 1e-3,
    "beta2": 0.99
  },
  "trainer": {
    "eval_interval": 250,
    "eval_iters": 200,
    "log_interval": 10,
    "always_save_checkpoint": false,
    "wandb_log": false,
    "wandb_project": "shakespeare-char",
    "wandb_run_name": "mini-gpt",
    "gradient_accumulation_steps": 1,
    "batch_size": 64,
    "max_iters": 5000,
    "warmup_iters": 100
  }
}