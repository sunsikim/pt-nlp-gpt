{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "462d0ff2-5bcc-4e07-aabc-2e4261f157ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pathlib\n",
    "import sys\n",
    "import torch\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from jobs.configure import GPT2Config\n",
    "from gpt.model import GPT2Attention\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4067ebe-1b8a-4b91-89ef-32ffddc368d3",
   "metadata": {},
   "source": [
    "For simplicity, configure the size of attention layer small as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b8db2a-4491-413a-bcc9-e005fa2f6a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Attention(\n",
       "  (c_attn): Linear(in_features=12, out_features=36, bias=False)\n",
       "  (c_proj): Linear(in_features=12, out_features=12, bias=False)\n",
       "  (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16  # denote as B\n",
    "token_count = 5  # denote as T\n",
    "embed_size = 12  # denote as S\n",
    "num_heads = 3    # denote as H\n",
    "\n",
    "cfg = GPT2Config(\n",
    "    block_size=token_count,\n",
    "    n_embd=embed_size,\n",
    "    n_head=num_heads,\n",
    ")\n",
    "layer = GPT2Attention(cfg)\n",
    "layer.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaa620b-d02d-4406-9c73-11e063843849",
   "metadata": {},
   "source": [
    "## Causal Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341f603e-c23a-4160-9a8d-52b261113503",
   "metadata": {},
   "source": [
    "Batch of token_ids will have shape of (B, T). If passed to embedding layer, resulting tensor will have shape of (B, T, S) illustrated as above. This causal attention layer will map this tensor into a new tensor of shape (B, T, S) after forward computation. This notebook will demonstrate the steps of this computation in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.randn(batch_size, cfg.block_size, cfg.n_embd)  # (B, T, S)\n",
    "B, T, S = input_tensor.size()\n",
    "original_output = layer(input_tensor)\n",
    "input_tensor.size() == original_output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a990d91-4397-4207-bde7-43c8212671f3",
   "metadata": {},
   "source": [
    "![input tensor](./images/causal_attention/input_tensor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772ea80f-85c0-43d8-b407-c0506f06ee1f",
   "metadata": {},
   "source": [
    "Dot product with weight matrix `c_attn` is calculated to map `input_tensor` into query, key, value tensor respsectively. Again, for simplicity, let's zoom into first tensor of a input_tensor only(i.e. `input_tensor[0]`) from now on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "929c8f60-1c37-497d-81a3-d7714e25c872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = layer.c_attn(input_tensor).split(S, dim=2)\n",
    "q.size() == k.size() == v.size() == input_tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a366db-2b70-4d47-9a93-31b66065f4b9",
   "metadata": {},
   "source": [
    "![qkv split](./images/causal_attention/qkv_split.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9393fe-300c-499d-b04a-51eeccf57d41",
   "metadata": {},
   "source": [
    "Each of query, key, value tensor is reshaped into tensor of shape (B, H, T, S // H), to represent input for each head in multi head attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e2a6613-1d60-42a8-9608-e314706c5ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 5, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = q.view(B, T, layer.num_heads, layer.head_dim).transpose(1, 2)\n",
    "k = k.view(B, T, layer.num_heads, layer.head_dim).transpose(1, 2)\n",
    "v = v.view(B, T, layer.num_heads, layer.head_dim).transpose(1, 2)\n",
    "q.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efb59de-49ff-4b7f-997d-5499410a81f0",
   "metadata": {},
   "source": [
    "![qkv split](./images/causal_attention/multihead_view.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713f1e7a-42f0-40e4-b04e-5ee1f5f7d78d",
   "metadata": {},
   "source": [
    "Then, to ensure only the attention over $1,\\ldots,i-1$-th tokens is applied on $i$-th token:\n",
    "1. dot product between query and key is calculated(i.e. softmax logits)\n",
    "2. upper triangular elements of this dot product are replaced to smallest value(-inf)\n",
    "3. softmax function is applied, to make this replaced value will result in 0 softmax value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08a28ec0-ecc0-4c6a-b97c-3bc72a9d44c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 5, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))     # scaled dot product\n",
    "att = att.masked_fill(layer.bias[:, :, :T, :T] == 0, float(\"-inf\")) # masked_fill\n",
    "att = F.softmax(att, dim=-1)\n",
    "y = att @ v\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f001f59-f105-4766-8b41-ba04ebf71a46",
   "metadata": {},
   "source": [
    "![qkv split](./images/causal_attention/masked_scaled_dot_product.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6dcb12-e1a0-4dd2-a6c7-aeeab228d7fb",
   "metadata": {},
   "source": [
    "Since resulting tensor `y` is still separated into H tensors, it has to be combined into single tensor. Note that `y` seemingly multiple tensors in this illustration, but as mentioned, it is actually (B, H, T, S // H) shaped single tensor. That is, it cannot be simply reshaped using `torch.stack` or `torch.cat`, therefore has to be manipulated by complex view arrangement as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f606119-e20b-4daf-baff-cfa0c0262de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 5, 12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.transpose(1, 2).contiguous().view(B, T, S)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7682ee34-c707-43dc-8fae-6d738cf233b8",
   "metadata": {},
   "source": [
    "![qkv split](./images/causal_attention/reshape.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70f8a30-cabc-4168-bed3-a18596584d30",
   "metadata": {},
   "source": [
    "After additional matrix multiplication with `c_proj` linear layer, this tensor becomes output of causal attention layer. This is then passed to lm_head and used as a logits for a softmax activation to compute cross entropy loss over next tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46c8e8e3-b2ad-4780-b7cf-810cf445be7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(layer.c_proj(y), original_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729438ad-17e1-4730-a998-28e7f698996a",
   "metadata": {},
   "source": [
    "## Key-Value Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1536a53c-429a-4474-9ef9-87053b40dc94",
   "metadata": {},
   "source": [
    "Now suppose that new token has appended and the system is asked to generate next token given this updated token sequence. For illustration, query, key, value elements already calculated from previous iteration are underlined and newly calculated elements are boldfaced.\n",
    "\n",
    "![qkv split](./images/kv_cache/qkv_split.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1b3b09-6eef-46ae-b7fa-6187fab9ede0",
   "metadata": {},
   "source": [
    "Below illustration demonstrates the flow of new token generation:\n",
    "\n",
    "1. As explained above, this query(q), key(k) tensors are devidened into H sub-tensors and their dot product is calculated to compute logits corresponding to the value(v).\n",
    "2. Also, each of dot product is then masked to calculate output tensor `y`.\n",
    "3. However, only the last row of `y` is used for next token generation. Although we still need every elements of value tensor, we only need last row of dot products in this context. Whitened cells in tensors represent such redundant elements in this softmax applied dot product.\n",
    "4. When rewinding calculation of this non-redundant logits, it turns out that only the last row in query tensor is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79763605-bd53-4aed-8a3f-bad19ef38fd1",
   "metadata": {},
   "source": [
    "![qkv split](./images/kv_cache/cache_flow.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a57fd0-e337-40d5-9f24-751a3595a98a",
   "metadata": {},
   "source": [
    "In conclusion, to generate next token more efficiently by dodging duplicated query, key, value computation:\n",
    "\n",
    "* Only the query, key, value that corresponds to new token has to be calculated\n",
    "* Other elements in key, value tensor should be cached to be reused to form full key, value tensor\n",
    "\n",
    "![qkv split](./images/kv_cache/conclusion.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
